{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f761251-f5aa-48dd-ae57-4225a045031b",
   "metadata": {},
   "source": [
    "# Assignment 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186aaaf-4f3b-40da-976e-db55629f78a4",
   "metadata": {},
   "source": [
    "## Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf43349-eb6f-4df8-bdf9-a97cf1533bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64f725-3a21-4781-9436-ee357217733c",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a67508f-7c64-4e04-8302-71e1b8782cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_path = \"./data/goblet_book.txt\"\n",
    "with open(book_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    book_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c6347c-e353-402f-9736-34824f11cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{book_data[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d57a49a-6521-4517-9664-3f46becbe6c2",
   "metadata": {},
   "source": [
    "## Exercise 1 - Implement and train vanilla RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f62f3-3913-469f-8f24-7ea1054aedfb",
   "metadata": {},
   "source": [
    "### 1.1 - Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57ef89-f227-4fea-9e14-62c94868b38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = list(set(book_data))\n",
    "char_to_id = {char: i for i, char in enumerate(unique_chars)}\n",
    "id_to_char = {i: char for i, char in enumerate(unique_chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773dfc38-b6e5-4921-bdcc-f3b1898bcc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"char -> id: {char_to_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05cf1e-936b-4db2-97e2-e539387324fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"char <- id: {id_to_char}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23858b1b-8409-40f0-af4f-c5f371d59821",
   "metadata": {},
   "source": [
    "### 1.2 - Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556ed6a-c317-4482-8889-62668e13244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(hidden_dim, output_dim, rng):\n",
    "    init_net = {}\n",
    "    init_net[\"b\"] = np.zeros((hidden_dim, 1))\n",
    "    init_net[\"c\"] = np.zeros((output_dim, 1))\n",
    "\n",
    "    init_net[\"U\"] = (1 / np.sqrt(2 * output_dim)) * rng.standard_normal(\n",
    "        size=(hidden_dim, output_dim)  # mxk\n",
    "    )\n",
    "    init_net[\"W\"] = (1 / np.sqrt(2 * hidden_dim)) * rng.standard_normal(\n",
    "        size=(hidden_dim, hidden_dim)  # mxm\n",
    "    )\n",
    "    init_net[\"V\"] = (1 / np.sqrt(hidden_dim)) * rng.standard_normal(\n",
    "        size=(output_dim, hidden_dim)  # kxm\n",
    "    )\n",
    "    return init_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff37d38-fd32-4760-ba62-a480cf591f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_network():\n",
    "    eta = 0.001\n",
    "    seq_length = 25\n",
    "    m = 100\n",
    "    K = len(unique_chars)\n",
    "    seed = 42\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "    init_net = initialize_network(m, K, rng)\n",
    "    return init_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca0b2a5-ff29-4b35-ab31-f58c17ef737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_init_net = init_network()\n",
    "print(\"initialize network...\")\n",
    "print(f\"init_network[U] shape -> {debug_init_net['U'].shape}\")\n",
    "print(f\"init_network[W] shape -> {debug_init_net['W'].shape}\")\n",
    "print(f\"init_network[V] shape -> {debug_init_net['V'].shape}\")\n",
    "print(f\"init_network[b] shape -> {debug_init_net['b'].shape}\")\n",
    "print(f\"init_network[c] shape -> {debug_init_net['c'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5ae111-efab-4ca5-b269-37a774e77d01",
   "metadata": {},
   "source": [
    "### 1.3 - Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066cc65-b94d-4dce-9930-6783912819d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Activation functions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# softmax function - not numerically stable according to stanford cs231n notes\n",
    "def softmax(s):\n",
    "    return np.exp(s) / np.sum(np.exp(s), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776fb8e4-35fe-4e82-94ac-4d41cd807c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_text(network, h0, x0, n, rng):\n",
    "    K = network[\"V\"].shape[0]\n",
    "    Y = np.zeros((K, n))\n",
    "\n",
    "    h = h0.copy()\n",
    "    x = x0.copy()\n",
    "\n",
    "    for t in range(n):\n",
    "        a = network[\"W\"] @ h + network[\"U\"] @ x + network[\"b\"]\n",
    "        h = np.tanh(a)\n",
    "        o = network[\"V\"] @ h + network[\"c\"]\n",
    "        p = softmax(o)\n",
    "\n",
    "        cp = np.cumsum(p, axis=0)\n",
    "        a = rng.uniform(size=1)\n",
    "        ii = np.argmax(cp - a > 0)\n",
    "\n",
    "        Y[ii, t] = 1\n",
    "\n",
    "        x = np.zeros((K, 1))\n",
    "        x[ii, 0] = 1\n",
    "\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cda593-d645-4ed3-890b-d6f23e8f89f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_chars(chars, char_to_id, K):\n",
    "    X = np.zeros((K, len(chars)))\n",
    "    for i, char in enumerate(chars):\n",
    "        if char in char_to_id:\n",
    "            X[char_to_id[char], i] = 1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64881c9e-a380-48b6-9f32-74144fdd7e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_chars(Y, ind_to_char):\n",
    "    indices = np.argmax(Y, axis=0)\n",
    "    text = \"\".join([ind_to_char[index] for index in indices])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde4847-66fc-437f-8bba-62d45f42eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(network, X, Y, h0):\n",
    "    K, seq_length = X.shape\n",
    "    m = network[\"W\"].shape[0]\n",
    "\n",
    "    h = np.zeros((m, seq_length + 1))\n",
    "    p = np.zeros((K, seq_length))\n",
    "\n",
    "    h[:, 0:1] = h0\n",
    "    loss = 0\n",
    "\n",
    "    for t in range(seq_length):\n",
    "        x_t = X[:, t : t + 1]\n",
    "        h_prev = h[:, t : t + 1]\n",
    "        a_t = network[\"W\"] @ h_prev + network[\"U\"] @ x_t + network[\"b\"]\n",
    "        h[:, t + 1 : t + 2] = np.tanh(a_t)\n",
    "        o_t = network[\"V\"] @ h[:, t + 1 : t + 2] + network[\"c\"]\n",
    "        p_t = softmax(o_t)\n",
    "        p[:, t : t + 1] = p_t\n",
    "\n",
    "        y_t = Y[:, t : t + 1]\n",
    "        loss += -np.sum(y_t * np.log(p_t + 1e-20))\n",
    "\n",
    "    loss = loss / seq_length\n",
    "\n",
    "    return loss, h, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18609437-260f-4cb0-aee2-332134c1e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(network, X, Y, h, p):\n",
    "    K, seq_length = X.shape\n",
    "    m = network[\"W\"].shape[0]\n",
    "    grads = {}\n",
    "    grads[\"dU\"] = np.zeros_like(network[\"U\"])  # m × K\n",
    "    grads[\"dW\"] = np.zeros_like(network[\"W\"])  # m × m\n",
    "    grads[\"dV\"] = np.zeros_like(network[\"V\"])  # K × m\n",
    "    grads[\"db\"] = np.zeros_like(network[\"b\"])  # m × 1\n",
    "    grads[\"dc\"] = np.zeros_like(network[\"c\"])  # K × 1\n",
    "\n",
    "    # initialize gradient for next time step\n",
    "    dh_next = np.zeros((m, 1))\n",
    "\n",
    "    for t in reversed(range(seq_length)):\n",
    "        y_t = Y[:, t : t + 1]\n",
    "        p_t = p[:, t : t + 1]\n",
    "        h_t = h[:, t + 1 : t + 2]\n",
    "        h_prev = h[:, t : t + 1]\n",
    "        x_t = X[:, t : t + 1]\n",
    "\n",
    "        # gradient of output\n",
    "        d_out = p_t - y_t\n",
    "\n",
    "        # gradient of v\n",
    "        grads[\"dV\"] += d_out @ h_t.T\n",
    "\n",
    "        # gradient of c\n",
    "        grads[\"dc\"] += d_out\n",
    "\n",
    "        # gradient of hidden\n",
    "        d_h = network[\"V\"].T @ d_out + dh_next\n",
    "\n",
    "        # gradient of a\n",
    "        d_a = d_h * (1 - h_t**2)\n",
    "\n",
    "        # gradient of W\n",
    "        grads[\"dW\"] += d_a @ h_prev.T\n",
    "\n",
    "        # gradient of U\n",
    "        grads[\"dU\"] += d_a @ x_t.T\n",
    "\n",
    "        # gradient of B\n",
    "        grads[\"db\"] += d_a\n",
    "\n",
    "        # gradient for next iteration\n",
    "        dh_next = network[\"W\"].T @ d_a\n",
    "\n",
    "    for key in grads:\n",
    "        grads[key] /= seq_length\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8982125e-24cb-4587-8b29-0a1c0044facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumes X has size d x tau, h0 has size m x 1, etc\n",
    "def ComputeGradsWithTorch(X, y, h0, RNN):\n",
    "    tau = X.shape[1]\n",
    "\n",
    "    Xt = torch.from_numpy(X)\n",
    "    ht = torch.from_numpy(h0)\n",
    "\n",
    "    torch_network = {}\n",
    "    for kk in RNN.keys():\n",
    "        torch_network[kk] = torch.tensor(RNN[kk], requires_grad=True)\n",
    "\n",
    "    ## give informative names to these torch classes\n",
    "    apply_tanh = torch.nn.Tanh()\n",
    "    apply_softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "    # create an empty tensor to store the hidden vector at each timestep\n",
    "    Hs = torch.empty(h0.shape[0], X.shape[1], dtype=torch.float64)\n",
    "\n",
    "    hprev = ht\n",
    "    for t in range(tau):\n",
    "        #### BEGIN your code ######\n",
    "\n",
    "        # Code to apply the RNN to hprev and Xt[:, t:t+1] to compute the hidden scores \"Hs\" at timestep t\n",
    "        x_t = Xt[:, t : t + 1]  # kx1\n",
    "\n",
    "        # (ie equations (1,2) in the assignment instructions)\n",
    "        a_t = (\n",
    "            torch.matmul(torch_network[\"W\"], hprev)\n",
    "            + torch.matmul(torch_network[\"U\"], x_t)\n",
    "            + torch_network[\"b\"]\n",
    "        )\n",
    "\n",
    "        h_t = apply_tanh(a_t)\n",
    "\n",
    "        # Store results in Hs\n",
    "        Hs[:, t : t + 1] = h_t\n",
    "\n",
    "        # Don't forget to update hprev!\n",
    "        hprev = h_t\n",
    "\n",
    "        #### END of your code ######\n",
    "\n",
    "    Os = torch.matmul(torch_network[\"V\"], Hs) + torch_network[\"c\"]\n",
    "    P = apply_softmax(Os)\n",
    "\n",
    "    # compute the loss\n",
    "\n",
    "    loss = torch.mean(-torch.log(P[y, np.arange(tau)]))\n",
    "\n",
    "    # compute the backward pass relative to the loss and the named parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # extract the computed gradients and make them numpy arrays\n",
    "    grads = {}\n",
    "    for kk in RNN.keys():\n",
    "        grads[kk] = torch_network[kk].grad.numpy()\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70721ae8-a359-4a1d-9302-9e9a1b260540",
   "metadata": {},
   "source": [
    "### 1.4 - Neural Networks go brrrr.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675519e-ffb2-4d6c-9f14-afa29a51d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_network():\n",
    "    rng = np.random.default_rng(42)\n",
    "    seq_length = 25\n",
    "    m = 10\n",
    "    X_chars = book_data[0:seq_length]\n",
    "    Y_chars = book_data[1 : seq_length + 1]\n",
    "    K = len(unique_chars)\n",
    "    X = encode_chars(X_chars, char_to_id, K)\n",
    "    Y = encode_chars(Y_chars, char_to_id, K)\n",
    "    h0 = np.zeros((m, 1))\n",
    "\n",
    "    init_net = initialize_network(m, K, rng)\n",
    "    loss, h, p = forward(init_net, X, Y, h0)\n",
    "    print(\n",
    "        f\"forward pass -> Loss: {loss:.4f}, h_shape: {h.shape}, p_shape: {p.shape}\"\n",
    "    )\n",
    "\n",
    "    y_indices = np.argmax(encode_chars(Y_chars, char_to_id, K), axis=0)\n",
    "    torch_grads = ComputeGradsWithTorch(X, y_indices, h0, init_net)\n",
    "    grads = backward(init_net, X, Y, h, p)\n",
    "\n",
    "    return torch_grads, grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc01f7ac-e4a8-4a1b-a494-de2b9de5d31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_error_check():\n",
    "    eps = 1e-6\n",
    "    torch_grads, my_grads = small_network()\n",
    "    abs_error_U = np.abs(my_grads[\"dU\"] - torch_grads[\"U\"])\n",
    "    abs_error_W = np.abs(my_grads[\"dW\"] - torch_grads[\"W\"])\n",
    "    abs_error_V = np.abs(my_grads[\"dV\"] - torch_grads[\"V\"])\n",
    "    abs_error_b = np.abs(my_grads[\"db\"] - torch_grads[\"b\"])\n",
    "    abs_error_c = np.abs(my_grads[\"dc\"] - torch_grads[\"c\"])\n",
    "    print(f\"U gradient check -> {np.all(abs_error_U < eps)}\")\n",
    "    print(f\"W gradient check -> {np.all(abs_error_W < eps)}\")\n",
    "    print(f\"V gradient check -> {np.all(abs_error_V < eps)}\")\n",
    "    print(f\"b gradient check -> {np.all(abs_error_b < eps)}\")\n",
    "    print(f\"c gradient check -> {np.all(abs_error_c < eps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ab120-d580-4acc-ad78-5408023e2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_error_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f2852-028f-4b2e-b840-10ca71108fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(loss_history, iter_history, filename=None):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(iter_history, loss_history)\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(\"Smooth Loss\")\n",
    "    plt.title(\"Smooth Loss - 4 Epochs\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "    if filename:\n",
    "        plt.savefig(f\"{filename}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a80ee6-0a55-4ef2-a9fe-9b350b2f2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text_history(text_samples, filename=\"text_evolution.txt\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        for sample in text_samples:\n",
    "            f.write(\n",
    "                f\"Iteration: {sample['iteration']}, Smooth Loss: {sample['loss']:.4f}\\n\"\n",
    "            )\n",
    "            f.write(f\"{sample['text']}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1258b-bb21-4e84-809f-f7ec94a87515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_final_text(network, char_to_id, id_to_char, rng, length=1000):\n",
    "    K = len(char_to_id)\n",
    "    hidden_dim = network[\"W\"].shape[0]\n",
    "    h0 = np.zeros((hidden_dim, 1))\n",
    "    x0 = np.zeros((K, 1))\n",
    "    x0[0, 0] = 1\n",
    "    Y_synth = synthesize_text(network, h0, x0, length, rng)\n",
    "    return decode_chars(Y_synth, id_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753cfc0-f90e-4068-bb23-6987eeba9bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn(\n",
    "    book_data,\n",
    "    char_to_id,\n",
    "    id_to_char,\n",
    "    network,\n",
    "    rng,\n",
    "    eta=0.001,\n",
    "    seq_length=25,\n",
    "    num_epochs=2,\n",
    "):\n",
    "    adam_params = {}\n",
    "    for key in network.keys():\n",
    "        adam_params[key] = {\n",
    "            \"m\": np.zeros_like(network[key]),\n",
    "            \"v\": np.zeros_like(network[key]),\n",
    "            \"t\": 0,\n",
    "        }\n",
    "\n",
    "    # adam hyperparameters\n",
    "    beta1 = 0.9\n",
    "    beta2 = 0.999\n",
    "    epsilon = 1e-8\n",
    "\n",
    "    e = 0\n",
    "    smooth_loss = None\n",
    "    hprev = np.zeros((network[\"W\"].shape[0], 1))\n",
    "    update = 0\n",
    "    K = len(unique_chars)\n",
    "\n",
    "    loss_history = []\n",
    "    iter_history = []\n",
    "    text_samples = []\n",
    "\n",
    "    best_smooth_loss = float(\"inf\")\n",
    "    best_network = None\n",
    "    best_update = 0\n",
    "\n",
    "    print(\"TRAIN THE RNN..............\")\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch: {epoch + 1}\")\n",
    "        while e <= len(book_data) - seq_length - 1:\n",
    "            X_chars = book_data[e : e + seq_length]\n",
    "            Y_chars = book_data[e + 1 : e + seq_length + 1]\n",
    "\n",
    "            X = encode_chars(X_chars, char_to_id, K)\n",
    "            Y = encode_chars(Y_chars, char_to_id, K)\n",
    "\n",
    "            loss, h, p = forward(network, X, Y, hprev)\n",
    "\n",
    "            if smooth_loss is None:\n",
    "                smooth_loss = loss\n",
    "            else:\n",
    "                smooth_loss = 0.999 * smooth_loss + 0.001 * loss\n",
    "\n",
    "            if smooth_loss < best_smooth_loss:\n",
    "                best_smooth_loss = smooth_loss\n",
    "                best_network = copy.deepcopy(network)\n",
    "                best_update = update\n",
    "                print(\n",
    "                    f\"Best model at iteration: {update}, smooth loss: {smooth_loss:.5f}\"\n",
    "                )\n",
    "\n",
    "            grads = backward(network, X, Y, h, p)\n",
    "\n",
    "            for key in network.keys():\n",
    "                adam_params[key][\"t\"] += 1\n",
    "                t = adam_params[key][\"t\"]\n",
    "                adam_params[key][\"m\"] = (\n",
    "                    beta1 * adam_params[key][\"m\"]\n",
    "                    + (1 - beta1) * grads[\"d\" + key]\n",
    "                )\n",
    "                adam_params[key][\"v\"] = beta2 * adam_params[key][\"v\"] + (\n",
    "                    1 - beta2\n",
    "                ) * (grads[\"d\" + key] ** 2)\n",
    "                m_hat = adam_params[key][\"m\"] / (1 - beta1**t)\n",
    "                v_hat = adam_params[key][\"v\"] / (1 - beta2**t)\n",
    "                network[key] = network[key] - eta * m_hat / (\n",
    "                    np.sqrt(v_hat) + epsilon\n",
    "                )\n",
    "\n",
    "            hprev = h[:, -1:]\n",
    "\n",
    "            if update % 100 == 0:\n",
    "                loss_history.append(smooth_loss)\n",
    "                iter_history.append(update)\n",
    "\n",
    "            if update == 0 or update % 1000 == 0:\n",
    "                print(f\"iter = {update}, smooth loss={smooth_loss}\")\n",
    "                Y_synth = synthesize_text(network, hprev, X[:, 0:1], 200, rng)\n",
    "                generated_text = decode_chars(Y_synth, id_to_char)\n",
    "                text_samples.append(\n",
    "                    {\n",
    "                        \"iteration\": update,\n",
    "                        \"text\": generated_text,\n",
    "                        \"loss\": smooth_loss,\n",
    "                    }\n",
    "                )\n",
    "                print(generated_text)\n",
    "                print()\n",
    "\n",
    "            e += seq_length\n",
    "            update += 1\n",
    "\n",
    "        print(f\"Completed epoch {epoch + 1}\")\n",
    "        e = 0\n",
    "        hprev = np.zeros((network[\"W\"].shape[0], 1))\n",
    "\n",
    "    print(\n",
    "        f\"\\nBest model achieved smooth loss: {best_smooth_loss:.5f} at iteration: {best_update}\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        network,\n",
    "        smooth_loss,\n",
    "        loss_history,\n",
    "        iter_history,\n",
    "        text_samples,\n",
    "        best_network,\n",
    "        best_smooth_loss,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abfb3e8-60bc-45f1-ab9c-72d1c33e36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.001\n",
    "seq_length = 25\n",
    "m = 100\n",
    "K = len(unique_chars)\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "network = initialize_network(m, K, rng)\n",
    "(\n",
    "    trained_network,\n",
    "    final_smooth_loss,\n",
    "    final_loss_history,\n",
    "    final_iter_history,\n",
    "    final_text_samples,\n",
    "    best_network,\n",
    "    best_smooth_loss,\n",
    ") = train_rnn(\n",
    "    book_data,\n",
    "    char_to_id,\n",
    "    id_to_char,\n",
    "    network,\n",
    "    rng,\n",
    "    eta=eta,\n",
    "    seq_length=seq_length,\n",
    "    num_epochs=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb6b76-b3e3-4ba7-9f8e-a7ba3e300a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(final_loss_history, final_iter_history, \"smooth_loss_results\")\n",
    "print_text_history(final_text_samples)\n",
    "print_final_text(best_network, char_to_id, id_to_char, rng, 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
